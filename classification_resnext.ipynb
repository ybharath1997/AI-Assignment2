{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib as mpl\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "from keras.layers.convolutional import Deconv2D as Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers import Add\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import sys\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras.layers import Input, merge, Dropout, Dense, Lambda, Flatten, Activation\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0/2000 images\n",
      "Done: 1/2000 images\n",
      "Done: 2/2000 images\n",
      "Done: 3/2000 images\n",
      "Done: 4/2000 images\n",
      "Done: 5/2000 images\n",
      "Done: 6/2000 images\n",
      "Done: 7/2000 images\n",
      "Done: 8/2000 images\n",
      "Done: 9/2000 images\n",
      "Done: 10/2000 images\n",
      "Done: 11/2000 images\n",
      "Done: 12/2000 images\n",
      "Done: 13/2000 images\n",
      "Done: 14/2000 images\n",
      "Done: 15/2000 images\n",
      "Done: 16/2000 images\n",
      "Done: 17/2000 images\n",
      "Done: 18/2000 images\n",
      "Done: 19/2000 images\n",
      "Done: 20/2000 images\n",
      "Done: 21/2000 images\n",
      "Done: 22/2000 images\n",
      "Done: 23/2000 images\n",
      "Done: 24/2000 images\n",
      "Done: 25/2000 images\n",
      "Done: 26/2000 images\n",
      "Done: 27/2000 images\n",
      "Done: 28/2000 images\n",
      "Done: 29/2000 images\n",
      "Done: 30/2000 images\n",
      "Done: 31/2000 images\n",
      "Done: 32/2000 images\n",
      "Done: 33/2000 images\n",
      "Done: 34/2000 images\n",
      "Done: 35/2000 images\n",
      "Done: 36/2000 images\n",
      "Done: 37/2000 images\n",
      "Done: 38/2000 images\n",
      "Done: 39/2000 images\n",
      "Done: 40/2000 images\n",
      "Done: 41/2000 images\n",
      "Done: 42/2000 images\n",
      "Done: 43/2000 images\n",
      "Done: 44/2000 images\n",
      "Done: 45/2000 images\n",
      "Done: 46/2000 images\n",
      "Done: 47/2000 images\n",
      "Done: 48/2000 images\n",
      "Done: 49/2000 images\n",
      "Done: 50/2000 images\n",
      "Done: 51/2000 images\n",
      "Done: 52/2000 images\n",
      "Done: 53/2000 images\n",
      "Done: 54/2000 images\n",
      "Done: 55/2000 images\n",
      "Done: 56/2000 images\n",
      "Done: 57/2000 images\n",
      "Done: 58/2000 images\n",
      "Done: 59/2000 images\n",
      "Done: 60/2000 images\n",
      "Done: 61/2000 images\n",
      "Done: 62/2000 images\n",
      "Done: 63/2000 images\n",
      "Done: 64/2000 images\n",
      "Done: 65/2000 images\n",
      "Done: 66/2000 images\n",
      "Done: 67/2000 images\n",
      "Done: 68/2000 images\n",
      "Done: 69/2000 images\n",
      "Done: 70/2000 images\n",
      "Done: 71/2000 images\n",
      "Done: 72/2000 images\n",
      "Done: 73/2000 images\n",
      "Done: 74/2000 images\n",
      "Done: 75/2000 images\n",
      "Done: 76/2000 images\n",
      "Done: 77/2000 images\n",
      "Done: 78/2000 images\n",
      "Done: 79/2000 images\n",
      "Done: 80/2000 images\n",
      "Done: 81/2000 images\n",
      "Done: 82/2000 images\n",
      "Done: 83/2000 images\n",
      "Done: 84/2000 images\n",
      "Done: 85/2000 images\n",
      "Done: 86/2000 images\n",
      "Done: 87/2000 images\n",
      "Done: 88/2000 images\n",
      "Done: 89/2000 images\n",
      "Done: 90/2000 images\n",
      "Done: 91/2000 images\n",
      "Done: 92/2000 images\n",
      "Done: 93/2000 images\n",
      "Done: 94/2000 images\n",
      "Done: 95/2000 images\n",
      "Done: 96/2000 images\n",
      "Done: 97/2000 images\n",
      "Done: 98/2000 images\n",
      "Done: 99/2000 images\n",
      "Done: 100/2000 images\n",
      "Done: 101/2000 images\n",
      "Done: 102/2000 images\n",
      "Done: 103/2000 images\n",
      "Done: 104/2000 images\n",
      "Done: 105/2000 images\n",
      "Done: 106/2000 images\n",
      "Done: 107/2000 images\n",
      "Done: 108/2000 images\n",
      "Done: 109/2000 images\n",
      "Done: 110/2000 images\n",
      "Done: 111/2000 images\n",
      "Done: 112/2000 images\n",
      "Done: 113/2000 images\n",
      "Done: 114/2000 images\n",
      "Done: 115/2000 images\n",
      "Done: 116/2000 images\n",
      "Done: 117/2000 images\n",
      "Done: 118/2000 images\n",
      "Done: 119/2000 images\n",
      "Done: 120/2000 images\n",
      "Done: 121/2000 images\n",
      "Done: 122/2000 images\n",
      "Done: 123/2000 images\n",
      "Done: 124/2000 images\n",
      "Done: 125/2000 images\n",
      "Done: 126/2000 images\n",
      "Done: 127/2000 images\n",
      "Done: 128/2000 images\n",
      "Done: 129/2000 images\n",
      "Done: 130/2000 images\n",
      "Done: 131/2000 images\n",
      "Done: 132/2000 images\n",
      "Done: 133/2000 images\n",
      "Done: 134/2000 images\n",
      "Done: 135/2000 images\n",
      "Done: 136/2000 images\n",
      "Done: 137/2000 images\n",
      "Done: 138/2000 images\n",
      "Done: 139/2000 images\n",
      "Done: 140/2000 images\n",
      "Done: 141/2000 images\n",
      "Done: 142/2000 images\n",
      "Done: 143/2000 images\n",
      "Done: 144/2000 images\n",
      "Done: 145/2000 images\n",
      "Done: 146/2000 images\n",
      "Done: 147/2000 images\n",
      "Done: 148/2000 images\n",
      "Done: 149/2000 images\n",
      "Done: 150/2000 images\n",
      "Done: 151/2000 images\n",
      "Done: 152/2000 images\n",
      "Done: 153/2000 images\n",
      "Done: 154/2000 images\n",
      "Done: 155/2000 images\n",
      "Done: 156/2000 images\n",
      "Done: 157/2000 images\n",
      "Done: 158/2000 images\n",
      "Done: 159/2000 images\n",
      "Done: 160/2000 images\n",
      "Done: 161/2000 images\n",
      "Done: 162/2000 images\n",
      "Done: 163/2000 images\n",
      "Done: 164/2000 images\n",
      "Done: 165/2000 images\n",
      "Done: 166/2000 images\n",
      "Done: 167/2000 images\n",
      "Done: 168/2000 images\n",
      "Done: 169/2000 images\n",
      "Done: 170/2000 images\n",
      "Done: 171/2000 images\n",
      "Done: 172/2000 images\n",
      "Done: 173/2000 images\n",
      "Done: 174/2000 images\n",
      "Done: 175/2000 images\n",
      "Done: 176/2000 images\n",
      "Done: 177/2000 images\n",
      "Done: 178/2000 images\n",
      "Done: 179/2000 images\n",
      "Done: 180/2000 images\n",
      "Done: 181/2000 images\n",
      "Done: 182/2000 images\n",
      "Done: 183/2000 images\n",
      "Done: 184/2000 images\n",
      "Done: 185/2000 images\n",
      "Done: 186/2000 images\n",
      "Done: 187/2000 images\n",
      "Done: 188/2000 images\n",
      "Done: 189/2000 images\n",
      "Done: 190/2000 images\n",
      "Done: 191/2000 images\n",
      "Done: 192/2000 images\n",
      "Done: 193/2000 images\n",
      "Done: 194/2000 images\n",
      "Done: 195/2000 images\n",
      "Done: 196/2000 images\n",
      "Done: 197/2000 images\n",
      "Done: 198/2000 images\n",
      "Done: 199/2000 images\n",
      "Done: 200/2000 images\n",
      "Done: 201/2000 images\n",
      "Done: 202/2000 images\n",
      "Done: 203/2000 images\n",
      "Done: 204/2000 images\n",
      "Done: 205/2000 images\n",
      "Done: 206/2000 images\n",
      "Done: 207/2000 images\n",
      "Done: 208/2000 images\n",
      "Done: 209/2000 images\n",
      "Done: 210/2000 images\n",
      "Done: 211/2000 images\n",
      "Done: 212/2000 images\n",
      "Done: 213/2000 images\n",
      "Done: 214/2000 images\n",
      "Done: 215/2000 images\n",
      "Done: 216/2000 images\n",
      "Done: 217/2000 images\n",
      "Done: 218/2000 images\n",
      "Done: 219/2000 images\n",
      "Done: 220/2000 images\n",
      "Done: 221/2000 images\n",
      "Done: 222/2000 images\n",
      "Done: 223/2000 images\n",
      "Done: 224/2000 images\n",
      "Done: 225/2000 images\n",
      "Done: 226/2000 images\n",
      "Done: 227/2000 images\n",
      "Done: 228/2000 images\n",
      "Done: 229/2000 images\n",
      "Done: 230/2000 images\n",
      "Done: 231/2000 images\n",
      "Done: 232/2000 images\n",
      "Done: 233/2000 images\n",
      "Done: 234/2000 images\n",
      "Done: 235/2000 images\n",
      "Done: 236/2000 images\n",
      "Done: 237/2000 images\n",
      "Done: 238/2000 images\n",
      "Done: 239/2000 images\n",
      "Done: 240/2000 images\n",
      "Done: 241/2000 images\n",
      "Done: 242/2000 images\n",
      "Done: 243/2000 images\n",
      "Done: 244/2000 images\n",
      "Done: 245/2000 images\n",
      "Done: 246/2000 images\n",
      "Done: 247/2000 images\n",
      "Done: 248/2000 images\n",
      "Done: 249/2000 images\n",
      "Done: 250/2000 images\n",
      "Done: 251/2000 images\n",
      "Done: 252/2000 images\n",
      "Done: 253/2000 images\n",
      "Done: 254/2000 images\n",
      "Done: 255/2000 images\n",
      "Done: 256/2000 images\n",
      "Done: 257/2000 images\n",
      "Done: 258/2000 images\n",
      "Done: 259/2000 images\n",
      "Done: 260/2000 images\n",
      "Done: 261/2000 images\n",
      "Done: 262/2000 images\n",
      "Done: 263/2000 images\n",
      "Done: 264/2000 images\n",
      "Done: 265/2000 images\n",
      "Done: 266/2000 images\n",
      "Done: 267/2000 images\n",
      "Done: 268/2000 images\n",
      "Done: 269/2000 images\n",
      "Done: 270/2000 images\n",
      "Done: 271/2000 images\n",
      "Done: 272/2000 images\n",
      "Done: 273/2000 images\n",
      "Done: 274/2000 images\n",
      "Done: 275/2000 images\n",
      "Done: 276/2000 images\n",
      "Done: 277/2000 images\n",
      "Done: 278/2000 images\n",
      "Done: 279/2000 images\n",
      "Done: 280/2000 images\n",
      "Done: 281/2000 images\n",
      "Done: 282/2000 images\n",
      "Done: 283/2000 images\n",
      "Done: 284/2000 images\n",
      "Done: 285/2000 images\n",
      "Done: 286/2000 images\n",
      "Done: 287/2000 images\n",
      "Done: 288/2000 images\n",
      "Done: 289/2000 images\n",
      "Done: 290/2000 images\n",
      "Done: 291/2000 images\n",
      "Done: 292/2000 images\n",
      "Done: 293/2000 images\n",
      "Done: 294/2000 images\n",
      "Done: 295/2000 images\n",
      "Done: 296/2000 images\n",
      "Done: 297/2000 images\n",
      "Done: 298/2000 images\n",
      "Done: 299/2000 images\n",
      "Done: 300/2000 images\n",
      "Done: 301/2000 images\n",
      "Done: 302/2000 images\n",
      "Done: 303/2000 images\n",
      "Done: 304/2000 images\n",
      "Done: 305/2000 images\n",
      "Done: 306/2000 images\n",
      "Done: 307/2000 images\n",
      "Done: 308/2000 images\n",
      "Done: 309/2000 images\n",
      "Done: 310/2000 images\n",
      "Done: 311/2000 images\n",
      "Done: 312/2000 images\n",
      "Done: 313/2000 images\n",
      "Done: 314/2000 images\n",
      "Done: 315/2000 images\n",
      "Done: 316/2000 images\n",
      "Done: 317/2000 images\n",
      "Done: 318/2000 images\n",
      "Done: 319/2000 images\n",
      "Done: 320/2000 images\n",
      "Done: 321/2000 images\n",
      "Done: 322/2000 images\n",
      "Done: 323/2000 images\n",
      "Done: 324/2000 images\n",
      "Done: 325/2000 images\n",
      "Done: 326/2000 images\n",
      "Done: 327/2000 images\n",
      "Done: 328/2000 images\n",
      "Done: 329/2000 images\n",
      "Done: 330/2000 images\n",
      "Done: 331/2000 images\n",
      "Done: 332/2000 images\n",
      "Done: 333/2000 images\n",
      "Done: 334/2000 images\n",
      "Done: 335/2000 images\n",
      "Done: 336/2000 images\n",
      "Done: 337/2000 images\n",
      "Done: 338/2000 images\n",
      "Done: 339/2000 images\n",
      "Done: 340/2000 images\n",
      "Done: 341/2000 images\n",
      "Done: 342/2000 images\n",
      "Done: 343/2000 images\n",
      "Done: 344/2000 images\n",
      "Done: 345/2000 images\n",
      "Done: 346/2000 images\n",
      "Done: 347/2000 images\n",
      "Done: 348/2000 images\n",
      "Done: 349/2000 images\n",
      "Done: 350/2000 images\n",
      "Done: 351/2000 images\n",
      "Done: 352/2000 images\n",
      "Done: 353/2000 images\n",
      "Done: 354/2000 images\n",
      "Done: 355/2000 images\n",
      "Done: 356/2000 images\n",
      "Done: 357/2000 images\n",
      "Done: 358/2000 images\n",
      "Done: 359/2000 images\n",
      "Done: 360/2000 images\n",
      "Done: 361/2000 images\n",
      "Done: 362/2000 images\n",
      "Done: 363/2000 images\n",
      "Done: 364/2000 images\n",
      "Done: 365/2000 images\n",
      "Done: 366/2000 images\n",
      "Done: 367/2000 images\n",
      "Done: 368/2000 images\n",
      "Done: 369/2000 images\n",
      "Done: 370/2000 images\n",
      "Done: 371/2000 images\n",
      "Done: 372/2000 images\n",
      "Done: 373/2000 images\n",
      "Done: 374/2000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "c:\\users\\ananda\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 375/2000 images\n",
      "Done: 376/2000 images\n",
      "Done: 377/2000 images\n",
      "Done: 378/2000 images\n",
      "Done: 379/2000 images\n",
      "Done: 380/2000 images\n",
      "Done: 381/2000 images\n",
      "Done: 382/2000 images\n",
      "Done: 383/2000 images\n",
      "Done: 384/2000 images\n",
      "Done: 385/2000 images\n",
      "Done: 386/2000 images\n",
      "Done: 387/2000 images\n",
      "Done: 388/2000 images\n",
      "Done: 389/2000 images\n",
      "Done: 390/2000 images\n",
      "Done: 391/2000 images\n",
      "Done: 392/2000 images\n",
      "Done: 393/2000 images\n",
      "Done: 394/2000 images\n",
      "Done: 395/2000 images\n",
      "Done: 396/2000 images\n",
      "Done: 397/2000 images\n",
      "Done: 398/2000 images\n",
      "Done: 399/2000 images\n",
      "Done: 400/2000 images\n",
      "Done: 401/2000 images\n",
      "Done: 402/2000 images\n",
      "Done: 403/2000 images\n",
      "Done: 404/2000 images\n",
      "Done: 405/2000 images\n",
      "Done: 406/2000 images\n",
      "Done: 407/2000 images\n",
      "Done: 408/2000 images\n",
      "Done: 409/2000 images\n",
      "Done: 410/2000 images\n",
      "Done: 411/2000 images\n",
      "Done: 412/2000 images\n",
      "Done: 413/2000 images\n",
      "Done: 414/2000 images\n",
      "Done: 415/2000 images\n",
      "Done: 416/2000 images\n",
      "Done: 417/2000 images\n",
      "Done: 418/2000 images\n",
      "Done: 419/2000 images\n",
      "Done: 420/2000 images\n",
      "Done: 421/2000 images\n",
      "Done: 422/2000 images\n",
      "Done: 423/2000 images\n",
      "Done: 424/2000 images\n",
      "Done: 425/2000 images\n",
      "Done: 426/2000 images\n",
      "Done: 427/2000 images\n",
      "Done: 428/2000 images\n",
      "Done: 429/2000 images\n",
      "Done: 430/2000 images\n",
      "Done: 431/2000 images\n",
      "Done: 432/2000 images\n",
      "Done: 433/2000 images\n",
      "Done: 434/2000 images\n",
      "Done: 435/2000 images\n",
      "Done: 436/2000 images\n",
      "Done: 437/2000 images\n",
      "Done: 438/2000 images\n",
      "Done: 439/2000 images\n",
      "Done: 440/2000 images\n",
      "Done: 441/2000 images\n",
      "Done: 442/2000 images\n",
      "Done: 443/2000 images\n",
      "Done: 444/2000 images\n",
      "Done: 445/2000 images\n",
      "Done: 446/2000 images\n",
      "Done: 447/2000 images\n",
      "Done: 448/2000 images\n",
      "Done: 449/2000 images\n",
      "Done: 450/2000 images\n",
      "Done: 451/2000 images\n",
      "Done: 452/2000 images\n",
      "Done: 453/2000 images\n",
      "Done: 454/2000 images\n",
      "Done: 455/2000 images\n",
      "Done: 456/2000 images\n",
      "Done: 457/2000 images\n",
      "Done: 458/2000 images\n",
      "Done: 459/2000 images\n",
      "Done: 460/2000 images\n",
      "Done: 461/2000 images\n",
      "Done: 462/2000 images\n",
      "Done: 463/2000 images\n",
      "Done: 464/2000 images\n",
      "Done: 465/2000 images\n",
      "Done: 466/2000 images\n",
      "Done: 467/2000 images\n",
      "Done: 468/2000 images\n",
      "Done: 469/2000 images\n",
      "Done: 470/2000 images\n",
      "Done: 471/2000 images\n",
      "Done: 472/2000 images\n",
      "Done: 473/2000 images\n",
      "Done: 474/2000 images\n",
      "Done: 475/2000 images\n",
      "Done: 476/2000 images\n",
      "Done: 477/2000 images\n",
      "Done: 478/2000 images\n",
      "Done: 479/2000 images\n",
      "Done: 480/2000 images\n",
      "Done: 481/2000 images\n",
      "Done: 482/2000 images\n",
      "Done: 483/2000 images\n",
      "Done: 484/2000 images\n",
      "Done: 485/2000 images\n",
      "Done: 486/2000 images\n",
      "Done: 487/2000 images\n",
      "Done: 488/2000 images\n",
      "Done: 489/2000 images\n",
      "Done: 490/2000 images\n",
      "Done: 491/2000 images\n",
      "Done: 492/2000 images\n",
      "Done: 493/2000 images\n",
      "Done: 494/2000 images\n",
      "Done: 495/2000 images\n",
      "Done: 496/2000 images\n",
      "Done: 497/2000 images\n",
      "Done: 498/2000 images\n",
      "Done: 499/2000 images\n",
      "Done: 500/2000 images\n",
      "Done: 501/2000 images\n",
      "Done: 502/2000 images\n",
      "Done: 503/2000 images\n",
      "Done: 504/2000 images\n",
      "Done: 505/2000 images\n",
      "Done: 506/2000 images\n",
      "Done: 507/2000 images\n",
      "Done: 508/2000 images\n",
      "Done: 509/2000 images\n",
      "Done: 510/2000 images\n",
      "Done: 511/2000 images\n",
      "Done: 512/2000 images\n",
      "Done: 513/2000 images\n",
      "Done: 514/2000 images\n",
      "Done: 515/2000 images\n",
      "Done: 516/2000 images\n",
      "Done: 517/2000 images\n",
      "Done: 518/2000 images\n",
      "Done: 519/2000 images\n",
      "Done: 520/2000 images\n",
      "Done: 521/2000 images\n",
      "Done: 522/2000 images\n",
      "Done: 523/2000 images\n",
      "Done: 524/2000 images\n",
      "Done: 525/2000 images\n",
      "Done: 526/2000 images\n",
      "Done: 527/2000 images\n",
      "Done: 528/2000 images\n",
      "Done: 529/2000 images\n",
      "Done: 530/2000 images\n",
      "Done: 531/2000 images\n",
      "Done: 532/2000 images\n",
      "Done: 533/2000 images\n",
      "Done: 534/2000 images\n",
      "Done: 535/2000 images\n",
      "Done: 536/2000 images\n",
      "Done: 537/2000 images\n",
      "Done: 538/2000 images\n",
      "Done: 539/2000 images\n",
      "Done: 540/2000 images\n",
      "Done: 541/2000 images\n",
      "Done: 542/2000 images\n",
      "Done: 543/2000 images\n",
      "Done: 544/2000 images\n",
      "Done: 545/2000 images\n",
      "Done: 546/2000 images\n",
      "Done: 547/2000 images\n",
      "Done: 548/2000 images\n",
      "Done: 549/2000 images\n",
      "Done: 550/2000 images\n",
      "Done: 551/2000 images\n",
      "Done: 552/2000 images\n",
      "Done: 553/2000 images\n",
      "Done: 554/2000 images\n",
      "Done: 555/2000 images\n",
      "Done: 556/2000 images\n",
      "Done: 557/2000 images\n",
      "Done: 558/2000 images\n",
      "Done: 559/2000 images\n",
      "Done: 560/2000 images\n",
      "Done: 561/2000 images\n",
      "Done: 562/2000 images\n",
      "Done: 563/2000 images\n",
      "Done: 564/2000 images\n",
      "Done: 565/2000 images\n",
      "Done: 566/2000 images\n",
      "Done: 567/2000 images\n",
      "Done: 568/2000 images\n",
      "Done: 569/2000 images\n",
      "Done: 570/2000 images\n",
      "Done: 571/2000 images\n",
      "Done: 572/2000 images\n",
      "Done: 573/2000 images\n",
      "Done: 574/2000 images\n",
      "Done: 575/2000 images\n",
      "Done: 576/2000 images\n",
      "Done: 577/2000 images\n",
      "Done: 578/2000 images\n",
      "Done: 579/2000 images\n",
      "Done: 580/2000 images\n",
      "Done: 581/2000 images\n",
      "Done: 582/2000 images\n",
      "Done: 583/2000 images\n",
      "Done: 584/2000 images\n",
      "Done: 585/2000 images\n",
      "Done: 586/2000 images\n",
      "Done: 587/2000 images\n",
      "Done: 588/2000 images\n",
      "Done: 589/2000 images\n",
      "Done: 590/2000 images\n",
      "Done: 591/2000 images\n",
      "Done: 592/2000 images\n",
      "Done: 593/2000 images\n",
      "Done: 594/2000 images\n",
      "Done: 595/2000 images\n",
      "Done: 596/2000 images\n",
      "Done: 597/2000 images\n",
      "Done: 598/2000 images\n",
      "Done: 599/2000 images\n",
      "Done: 600/2000 images\n",
      "Done: 601/2000 images\n",
      "Done: 602/2000 images\n",
      "Done: 603/2000 images\n",
      "Done: 604/2000 images\n",
      "Done: 605/2000 images\n",
      "Done: 606/2000 images\n",
      "Done: 607/2000 images\n",
      "Done: 608/2000 images\n",
      "Done: 609/2000 images\n",
      "Done: 610/2000 images\n",
      "Done: 611/2000 images\n",
      "Done: 612/2000 images\n",
      "Done: 613/2000 images\n",
      "Done: 614/2000 images\n",
      "Done: 615/2000 images\n",
      "Done: 616/2000 images\n",
      "Done: 617/2000 images\n",
      "Done: 618/2000 images\n",
      "Done: 619/2000 images\n",
      "Done: 620/2000 images\n",
      "Done: 621/2000 images\n",
      "Done: 622/2000 images\n",
      "Done: 623/2000 images\n",
      "Done: 624/2000 images\n",
      "Done: 625/2000 images\n",
      "Done: 626/2000 images\n",
      "Done: 627/2000 images\n",
      "Done: 628/2000 images\n",
      "Done: 629/2000 images\n",
      "Done: 630/2000 images\n",
      "Done: 631/2000 images\n",
      "Done: 632/2000 images\n",
      "Done: 633/2000 images\n",
      "Done: 634/2000 images\n",
      "Done: 635/2000 images\n",
      "Done: 636/2000 images\n",
      "Done: 637/2000 images\n",
      "Done: 638/2000 images\n",
      "Done: 639/2000 images\n",
      "Done: 640/2000 images\n",
      "Done: 641/2000 images\n",
      "Done: 642/2000 images\n",
      "Done: 643/2000 images\n",
      "Done: 644/2000 images\n",
      "Done: 645/2000 images\n",
      "Done: 646/2000 images\n",
      "Done: 647/2000 images\n",
      "Done: 648/2000 images\n",
      "Done: 649/2000 images\n",
      "Done: 650/2000 images\n",
      "Done: 651/2000 images\n",
      "Done: 652/2000 images\n",
      "Done: 653/2000 images\n",
      "Done: 654/2000 images\n",
      "Done: 655/2000 images\n",
      "Done: 656/2000 images\n",
      "Done: 657/2000 images\n",
      "Done: 658/2000 images\n",
      "Done: 659/2000 images\n",
      "Done: 660/2000 images\n",
      "Done: 661/2000 images\n",
      "Done: 662/2000 images\n",
      "Done: 663/2000 images\n",
      "Done: 664/2000 images\n",
      "Done: 665/2000 images\n",
      "Done: 666/2000 images\n",
      "Done: 667/2000 images\n",
      "Done: 668/2000 images\n",
      "Done: 669/2000 images\n",
      "Done: 670/2000 images\n",
      "Done: 671/2000 images\n",
      "Done: 672/2000 images\n",
      "Done: 673/2000 images\n",
      "Done: 674/2000 images\n",
      "Done: 675/2000 images\n",
      "Done: 676/2000 images\n",
      "Done: 677/2000 images\n",
      "Done: 678/2000 images\n",
      "Done: 679/2000 images\n",
      "Done: 680/2000 images\n",
      "Done: 681/2000 images\n",
      "Done: 682/2000 images\n",
      "Done: 683/2000 images\n",
      "Done: 684/2000 images\n",
      "Done: 685/2000 images\n",
      "Done: 686/2000 images\n",
      "Done: 687/2000 images\n",
      "Done: 688/2000 images\n",
      "Done: 689/2000 images\n",
      "Done: 690/2000 images\n",
      "Done: 691/2000 images\n",
      "Done: 692/2000 images\n",
      "Done: 693/2000 images\n",
      "Done: 694/2000 images\n",
      "Done: 695/2000 images\n",
      "Done: 696/2000 images\n",
      "Done: 697/2000 images\n",
      "Done: 698/2000 images\n",
      "Done: 699/2000 images\n",
      "Done: 700/2000 images\n",
      "Done: 701/2000 images\n",
      "Done: 702/2000 images\n",
      "Done: 703/2000 images\n",
      "Done: 704/2000 images\n",
      "Done: 705/2000 images\n",
      "Done: 706/2000 images\n",
      "Done: 707/2000 images\n",
      "Done: 708/2000 images\n",
      "Done: 709/2000 images\n",
      "Done: 710/2000 images\n",
      "Done: 711/2000 images\n",
      "Done: 712/2000 images\n",
      "Done: 713/2000 images\n",
      "Done: 714/2000 images\n",
      "Done: 715/2000 images\n",
      "Done: 716/2000 images\n",
      "Done: 717/2000 images\n",
      "Done: 718/2000 images\n",
      "Done: 719/2000 images\n",
      "Done: 720/2000 images\n",
      "Done: 721/2000 images\n",
      "Done: 722/2000 images\n",
      "Done: 723/2000 images\n",
      "Done: 724/2000 images\n",
      "Done: 725/2000 images\n",
      "Done: 726/2000 images\n",
      "Done: 727/2000 images\n",
      "Done: 728/2000 images\n",
      "Done: 729/2000 images\n",
      "Done: 730/2000 images\n",
      "Done: 731/2000 images\n",
      "Done: 732/2000 images\n",
      "Done: 733/2000 images\n",
      "Done: 734/2000 images\n",
      "Done: 735/2000 images\n",
      "Done: 736/2000 images\n",
      "Done: 737/2000 images\n",
      "Done: 738/2000 images\n",
      "Done: 739/2000 images\n",
      "Done: 740/2000 images\n",
      "Done: 741/2000 images\n",
      "Done: 742/2000 images\n",
      "Done: 743/2000 images\n",
      "Done: 744/2000 images\n",
      "Done: 745/2000 images\n",
      "Done: 746/2000 images\n",
      "Done: 747/2000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 748/2000 images\n",
      "Done: 749/2000 images\n",
      "Done: 750/2000 images\n",
      "Done: 751/2000 images\n",
      "Done: 752/2000 images\n",
      "Done: 753/2000 images\n",
      "Done: 754/2000 images\n",
      "Done: 755/2000 images\n",
      "Done: 756/2000 images\n",
      "Done: 757/2000 images\n",
      "Done: 758/2000 images\n",
      "Done: 759/2000 images\n",
      "Done: 760/2000 images\n",
      "Done: 761/2000 images\n",
      "Done: 762/2000 images\n",
      "Done: 763/2000 images\n",
      "Done: 764/2000 images\n",
      "Done: 765/2000 images\n",
      "Done: 766/2000 images\n",
      "Done: 767/2000 images\n",
      "Done: 768/2000 images\n",
      "Done: 769/2000 images\n",
      "Done: 770/2000 images\n",
      "Done: 771/2000 images\n",
      "Done: 772/2000 images\n",
      "Done: 773/2000 images\n",
      "Done: 774/2000 images\n",
      "Done: 775/2000 images\n",
      "Done: 776/2000 images\n",
      "Done: 777/2000 images\n",
      "Done: 778/2000 images\n",
      "Done: 779/2000 images\n",
      "Done: 780/2000 images\n",
      "Done: 781/2000 images\n",
      "Done: 782/2000 images\n",
      "Done: 783/2000 images\n",
      "Done: 784/2000 images\n",
      "Done: 785/2000 images\n",
      "Done: 786/2000 images\n",
      "Done: 787/2000 images\n",
      "Done: 788/2000 images\n",
      "Done: 789/2000 images\n",
      "Done: 790/2000 images\n",
      "Done: 791/2000 images\n",
      "Done: 792/2000 images\n",
      "Done: 793/2000 images\n",
      "Done: 794/2000 images\n",
      "Done: 795/2000 images\n",
      "Done: 796/2000 images\n",
      "Done: 797/2000 images\n",
      "Done: 798/2000 images\n",
      "Done: 799/2000 images\n",
      "Done: 800/2000 images\n",
      "Done: 801/2000 images\n",
      "Done: 802/2000 images\n",
      "Done: 803/2000 images\n",
      "Done: 804/2000 images\n",
      "Done: 805/2000 images\n",
      "Done: 806/2000 images\n",
      "Done: 807/2000 images\n",
      "Done: 808/2000 images\n",
      "Done: 809/2000 images\n",
      "Done: 810/2000 images\n",
      "Done: 811/2000 images\n",
      "Done: 812/2000 images\n",
      "Done: 813/2000 images\n",
      "Done: 814/2000 images\n",
      "Done: 815/2000 images\n",
      "Done: 816/2000 images\n",
      "Done: 817/2000 images\n",
      "Done: 818/2000 images\n",
      "Done: 819/2000 images\n",
      "Done: 820/2000 images\n",
      "Done: 821/2000 images\n",
      "Done: 822/2000 images\n",
      "Done: 823/2000 images\n",
      "Done: 824/2000 images\n",
      "Done: 825/2000 images\n",
      "Done: 826/2000 images\n",
      "Done: 827/2000 images\n",
      "Done: 828/2000 images\n",
      "Done: 829/2000 images\n",
      "Done: 830/2000 images\n",
      "Done: 831/2000 images\n",
      "Done: 832/2000 images\n",
      "Done: 833/2000 images\n",
      "Done: 834/2000 images\n",
      "Done: 835/2000 images\n",
      "Done: 836/2000 images\n",
      "Done: 837/2000 images\n",
      "Done: 838/2000 images\n",
      "Done: 839/2000 images\n",
      "Done: 840/2000 images\n",
      "Done: 841/2000 images\n",
      "Done: 842/2000 images\n",
      "Done: 843/2000 images\n",
      "Done: 844/2000 images\n",
      "Done: 845/2000 images\n",
      "Done: 846/2000 images\n",
      "Done: 847/2000 images\n",
      "Done: 848/2000 images\n",
      "Done: 849/2000 images\n",
      "Done: 850/2000 images\n",
      "Done: 851/2000 images\n",
      "Done: 852/2000 images\n",
      "Done: 853/2000 images\n",
      "Done: 854/2000 images\n",
      "Done: 855/2000 images\n",
      "Done: 856/2000 images\n",
      "Done: 857/2000 images\n",
      "Done: 858/2000 images\n",
      "Done: 859/2000 images\n",
      "Done: 860/2000 images\n",
      "Done: 861/2000 images\n",
      "Done: 862/2000 images\n",
      "Done: 863/2000 images\n",
      "Done: 864/2000 images\n",
      "Done: 865/2000 images\n",
      "Done: 866/2000 images\n",
      "Done: 867/2000 images\n",
      "Done: 868/2000 images\n",
      "Done: 869/2000 images\n",
      "Done: 870/2000 images\n",
      "Done: 871/2000 images\n",
      "Done: 872/2000 images\n",
      "Done: 873/2000 images\n",
      "Done: 874/2000 images\n",
      "Done: 875/2000 images\n",
      "Done: 876/2000 images\n",
      "Done: 877/2000 images\n",
      "Done: 878/2000 images\n",
      "Done: 879/2000 images\n",
      "Done: 880/2000 images\n",
      "Done: 881/2000 images\n",
      "Done: 882/2000 images\n",
      "Done: 883/2000 images\n",
      "Done: 884/2000 images\n",
      "Done: 885/2000 images\n",
      "Done: 886/2000 images\n",
      "Done: 887/2000 images\n",
      "Done: 888/2000 images\n",
      "Done: 889/2000 images\n",
      "Done: 890/2000 images\n",
      "Done: 891/2000 images\n",
      "Done: 892/2000 images\n",
      "Done: 893/2000 images\n",
      "Done: 894/2000 images\n",
      "Done: 895/2000 images\n",
      "Done: 896/2000 images\n",
      "Done: 897/2000 images\n",
      "Done: 898/2000 images\n",
      "Done: 899/2000 images\n",
      "Done: 900/2000 images\n",
      "Done: 901/2000 images\n",
      "Done: 902/2000 images\n",
      "Done: 903/2000 images\n",
      "Done: 904/2000 images\n",
      "Done: 905/2000 images\n",
      "Done: 906/2000 images\n",
      "Done: 907/2000 images\n",
      "Done: 908/2000 images\n",
      "Done: 909/2000 images\n",
      "Done: 910/2000 images\n",
      "Done: 911/2000 images\n",
      "Done: 912/2000 images\n",
      "Done: 913/2000 images\n",
      "Done: 914/2000 images\n",
      "Done: 915/2000 images\n",
      "Done: 916/2000 images\n",
      "Done: 917/2000 images\n",
      "Done: 918/2000 images\n",
      "Done: 919/2000 images\n",
      "Done: 920/2000 images\n",
      "Done: 921/2000 images\n",
      "Done: 922/2000 images\n",
      "Done: 923/2000 images\n",
      "Done: 924/2000 images\n",
      "Done: 925/2000 images\n",
      "Done: 926/2000 images\n",
      "Done: 927/2000 images\n",
      "Done: 928/2000 images\n",
      "Done: 929/2000 images\n",
      "Done: 930/2000 images\n",
      "Done: 931/2000 images\n",
      "Done: 932/2000 images\n",
      "Done: 933/2000 images\n",
      "Done: 934/2000 images\n",
      "Done: 935/2000 images\n",
      "Done: 936/2000 images\n",
      "Done: 937/2000 images\n",
      "Done: 938/2000 images\n",
      "Done: 939/2000 images\n",
      "Done: 940/2000 images\n",
      "Done: 941/2000 images\n",
      "Done: 942/2000 images\n",
      "Done: 943/2000 images\n",
      "Done: 944/2000 images\n",
      "Done: 945/2000 images\n",
      "Done: 946/2000 images\n",
      "Done: 947/2000 images\n",
      "Done: 948/2000 images\n",
      "Done: 949/2000 images\n",
      "Done: 950/2000 images\n",
      "Done: 951/2000 images\n",
      "Done: 952/2000 images\n",
      "Done: 953/2000 images\n",
      "Done: 954/2000 images\n",
      "Done: 955/2000 images\n",
      "Done: 956/2000 images\n",
      "Done: 957/2000 images\n",
      "Done: 958/2000 images\n",
      "Done: 959/2000 images\n",
      "Done: 960/2000 images\n",
      "Done: 961/2000 images\n",
      "Done: 962/2000 images\n",
      "Done: 963/2000 images\n",
      "Done: 964/2000 images\n",
      "Done: 965/2000 images\n",
      "Done: 966/2000 images\n",
      "Done: 967/2000 images\n",
      "Done: 968/2000 images\n",
      "Done: 969/2000 images\n",
      "Done: 970/2000 images\n",
      "Done: 971/2000 images\n",
      "Done: 972/2000 images\n",
      "Done: 973/2000 images\n",
      "Done: 974/2000 images\n",
      "Done: 975/2000 images\n",
      "Done: 976/2000 images\n",
      "Done: 977/2000 images\n",
      "Done: 978/2000 images\n",
      "Done: 979/2000 images\n",
      "Done: 980/2000 images\n",
      "Done: 981/2000 images\n",
      "Done: 982/2000 images\n",
      "Done: 983/2000 images\n",
      "Done: 984/2000 images\n",
      "Done: 985/2000 images\n",
      "Done: 986/2000 images\n",
      "Done: 987/2000 images\n",
      "Done: 988/2000 images\n",
      "Done: 989/2000 images\n",
      "Done: 990/2000 images\n",
      "Done: 991/2000 images\n",
      "Done: 992/2000 images\n",
      "Done: 993/2000 images\n",
      "Done: 994/2000 images\n",
      "Done: 995/2000 images\n",
      "Done: 996/2000 images\n",
      "Done: 997/2000 images\n",
      "Done: 998/2000 images\n",
      "Done: 999/2000 images\n",
      "Done: 1000/2000 images\n",
      "Done: 1001/2000 images\n",
      "Done: 1002/2000 images\n",
      "Done: 1003/2000 images\n",
      "Done: 1004/2000 images\n",
      "Done: 1005/2000 images\n",
      "Done: 1006/2000 images\n",
      "Done: 1007/2000 images\n",
      "Done: 1008/2000 images\n",
      "Done: 1009/2000 images\n",
      "Done: 1010/2000 images\n",
      "Done: 1011/2000 images\n",
      "Done: 1012/2000 images\n",
      "Done: 1013/2000 images\n",
      "Done: 1014/2000 images\n",
      "Done: 1015/2000 images\n",
      "Done: 1016/2000 images\n",
      "Done: 1017/2000 images\n",
      "Done: 1018/2000 images\n",
      "Done: 1019/2000 images\n",
      "Done: 1020/2000 images\n",
      "Done: 1021/2000 images\n",
      "Done: 1022/2000 images\n",
      "Done: 1023/2000 images\n",
      "Done: 1024/2000 images\n",
      "Done: 1025/2000 images\n",
      "Done: 1026/2000 images\n",
      "Done: 1027/2000 images\n",
      "Done: 1028/2000 images\n",
      "Done: 1029/2000 images\n",
      "Done: 1030/2000 images\n",
      "Done: 1031/2000 images\n",
      "Done: 1032/2000 images\n",
      "Done: 1033/2000 images\n",
      "Done: 1034/2000 images\n",
      "Done: 1035/2000 images\n",
      "Done: 1036/2000 images\n",
      "Done: 1037/2000 images\n",
      "Done: 1038/2000 images\n",
      "Done: 1039/2000 images\n",
      "Done: 1040/2000 images\n",
      "Done: 1041/2000 images\n",
      "Done: 1042/2000 images\n",
      "Done: 1043/2000 images\n",
      "Done: 1044/2000 images\n",
      "Done: 1045/2000 images\n",
      "Done: 1046/2000 images\n",
      "Done: 1047/2000 images\n",
      "Done: 1048/2000 images\n",
      "Done: 1049/2000 images\n",
      "Done: 1050/2000 images\n",
      "Done: 1051/2000 images\n",
      "Done: 1052/2000 images\n",
      "Done: 1053/2000 images\n",
      "Done: 1054/2000 images\n",
      "Done: 1055/2000 images\n",
      "Done: 1056/2000 images\n",
      "Done: 1057/2000 images\n",
      "Done: 1058/2000 images\n",
      "Done: 1059/2000 images\n",
      "Done: 1060/2000 images\n",
      "Done: 1061/2000 images\n",
      "Done: 1062/2000 images\n",
      "Done: 1063/2000 images\n",
      "Done: 1064/2000 images\n",
      "Done: 1065/2000 images\n",
      "Done: 1066/2000 images\n",
      "Done: 1067/2000 images\n",
      "Done: 1068/2000 images\n",
      "Done: 1069/2000 images\n",
      "Done: 1070/2000 images\n",
      "Done: 1071/2000 images\n",
      "Done: 1072/2000 images\n",
      "Done: 1073/2000 images\n",
      "Done: 1074/2000 images\n",
      "Done: 1075/2000 images\n",
      "Done: 1076/2000 images\n",
      "Done: 1077/2000 images\n",
      "Done: 1078/2000 images\n",
      "Done: 1079/2000 images\n",
      "Done: 1080/2000 images\n",
      "Done: 1081/2000 images\n",
      "Done: 1082/2000 images\n",
      "Done: 1083/2000 images\n",
      "Done: 1084/2000 images\n",
      "Done: 1085/2000 images\n",
      "Done: 1086/2000 images\n",
      "Done: 1087/2000 images\n",
      "Done: 1088/2000 images\n",
      "Done: 1089/2000 images\n",
      "Done: 1090/2000 images\n",
      "Done: 1091/2000 images\n",
      "Done: 1092/2000 images\n",
      "Done: 1093/2000 images\n",
      "Done: 1094/2000 images\n",
      "Done: 1095/2000 images\n",
      "Done: 1096/2000 images\n",
      "Done: 1097/2000 images\n",
      "Done: 1098/2000 images\n",
      "Done: 1099/2000 images\n",
      "Done: 1100/2000 images\n",
      "Done: 1101/2000 images\n",
      "Done: 1102/2000 images\n",
      "Done: 1103/2000 images\n",
      "Done: 1104/2000 images\n",
      "Done: 1105/2000 images\n",
      "Done: 1106/2000 images\n",
      "Done: 1107/2000 images\n",
      "Done: 1108/2000 images\n",
      "Done: 1109/2000 images\n",
      "Done: 1110/2000 images\n",
      "Done: 1111/2000 images\n",
      "Done: 1112/2000 images\n",
      "Done: 1113/2000 images\n",
      "Done: 1114/2000 images\n",
      "Done: 1115/2000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1116/2000 images\n",
      "Done: 1117/2000 images\n",
      "Done: 1118/2000 images\n",
      "Done: 1119/2000 images\n",
      "Done: 1120/2000 images\n",
      "Done: 1121/2000 images\n",
      "Done: 1122/2000 images\n",
      "Done: 1123/2000 images\n",
      "Done: 1124/2000 images\n",
      "Done: 1125/2000 images\n",
      "Done: 1126/2000 images\n",
      "Done: 1127/2000 images\n",
      "Done: 1128/2000 images\n",
      "Done: 1129/2000 images\n",
      "Done: 1130/2000 images\n",
      "Done: 1131/2000 images\n",
      "Done: 1132/2000 images\n",
      "Done: 1133/2000 images\n",
      "Done: 1134/2000 images\n",
      "Done: 1135/2000 images\n",
      "Done: 1136/2000 images\n",
      "Done: 1137/2000 images\n",
      "Done: 1138/2000 images\n",
      "Done: 1139/2000 images\n",
      "Done: 1140/2000 images\n",
      "Done: 1141/2000 images\n",
      "Done: 1142/2000 images\n",
      "Done: 1143/2000 images\n",
      "Done: 1144/2000 images\n",
      "Done: 1145/2000 images\n",
      "Done: 1146/2000 images\n",
      "Done: 1147/2000 images\n",
      "Done: 1148/2000 images\n",
      "Done: 1149/2000 images\n",
      "Done: 1150/2000 images\n",
      "Done: 1151/2000 images\n",
      "Done: 1152/2000 images\n",
      "Done: 1153/2000 images\n",
      "Done: 1154/2000 images\n",
      "Done: 1155/2000 images\n",
      "Done: 1156/2000 images\n",
      "Done: 1157/2000 images\n",
      "Done: 1158/2000 images\n",
      "Done: 1159/2000 images\n",
      "Done: 1160/2000 images\n",
      "Done: 1161/2000 images\n",
      "Done: 1162/2000 images\n",
      "Done: 1163/2000 images\n",
      "Done: 1164/2000 images\n",
      "Done: 1165/2000 images\n",
      "Done: 1166/2000 images\n",
      "Done: 1167/2000 images\n",
      "Done: 1168/2000 images\n",
      "Done: 1169/2000 images\n",
      "Done: 1170/2000 images\n",
      "Done: 1171/2000 images\n",
      "Done: 1172/2000 images\n",
      "Done: 1173/2000 images\n",
      "Done: 1174/2000 images\n",
      "Done: 1175/2000 images\n",
      "Done: 1176/2000 images\n",
      "Done: 1177/2000 images\n",
      "Done: 1178/2000 images\n",
      "Done: 1179/2000 images\n",
      "Done: 1180/2000 images\n",
      "Done: 1181/2000 images\n",
      "Done: 1182/2000 images\n",
      "Done: 1183/2000 images\n",
      "Done: 1184/2000 images\n",
      "Done: 1185/2000 images\n",
      "Done: 1186/2000 images\n",
      "Done: 1187/2000 images\n",
      "Done: 1188/2000 images\n",
      "Done: 1189/2000 images\n",
      "Done: 1190/2000 images\n",
      "Done: 1191/2000 images\n",
      "Done: 1192/2000 images\n",
      "Done: 1193/2000 images\n",
      "Done: 1194/2000 images\n",
      "Done: 1195/2000 images\n",
      "Done: 1196/2000 images\n",
      "Done: 1197/2000 images\n",
      "Done: 1198/2000 images\n",
      "Done: 1199/2000 images\n",
      "Done: 1200/2000 images\n",
      "Done: 1201/2000 images\n",
      "Done: 1202/2000 images\n",
      "Done: 1203/2000 images\n",
      "Done: 1204/2000 images\n",
      "Done: 1205/2000 images\n",
      "Done: 1206/2000 images\n",
      "Done: 1207/2000 images\n",
      "Done: 1208/2000 images\n",
      "Done: 1209/2000 images\n",
      "Done: 1210/2000 images\n",
      "Done: 1211/2000 images\n",
      "Done: 1212/2000 images\n",
      "Done: 1213/2000 images\n",
      "Done: 1214/2000 images\n",
      "Done: 1215/2000 images\n",
      "Done: 1216/2000 images\n",
      "Done: 1217/2000 images\n",
      "Done: 1218/2000 images\n",
      "Done: 1219/2000 images\n",
      "Done: 1220/2000 images\n",
      "Done: 1221/2000 images\n",
      "Done: 1222/2000 images\n",
      "Done: 1223/2000 images\n",
      "Done: 1224/2000 images\n",
      "Done: 1225/2000 images\n",
      "Done: 1226/2000 images\n",
      "Done: 1227/2000 images\n",
      "Done: 1228/2000 images\n",
      "Done: 1229/2000 images\n",
      "Done: 1230/2000 images\n",
      "Done: 1231/2000 images\n",
      "Done: 1232/2000 images\n",
      "Done: 1233/2000 images\n",
      "Done: 1234/2000 images\n",
      "Done: 1235/2000 images\n",
      "Done: 1236/2000 images\n",
      "Done: 1237/2000 images\n",
      "Done: 1238/2000 images\n",
      "Done: 1239/2000 images\n",
      "Done: 1240/2000 images\n",
      "Done: 1241/2000 images\n",
      "Done: 1242/2000 images\n",
      "Done: 1243/2000 images\n",
      "Done: 1244/2000 images\n",
      "Done: 1245/2000 images\n",
      "Done: 1246/2000 images\n",
      "Done: 1247/2000 images\n",
      "Done: 1248/2000 images\n",
      "Done: 1249/2000 images\n",
      "Done: 1250/2000 images\n",
      "Done: 1251/2000 images\n",
      "Done: 1252/2000 images\n",
      "Done: 1253/2000 images\n",
      "Done: 1254/2000 images\n",
      "Done: 1255/2000 images\n",
      "Done: 1256/2000 images\n",
      "Done: 1257/2000 images\n",
      "Done: 1258/2000 images\n",
      "Done: 1259/2000 images\n",
      "Done: 1260/2000 images\n",
      "Done: 1261/2000 images\n",
      "Done: 1262/2000 images\n",
      "Done: 1263/2000 images\n",
      "Done: 1264/2000 images\n",
      "Done: 1265/2000 images\n",
      "Done: 1266/2000 images\n",
      "Done: 1267/2000 images\n",
      "Done: 1268/2000 images\n",
      "Done: 1269/2000 images\n",
      "Done: 1270/2000 images\n",
      "Done: 1271/2000 images\n",
      "Done: 1272/2000 images\n",
      "Done: 1273/2000 images\n",
      "Done: 1274/2000 images\n",
      "Done: 1275/2000 images\n",
      "Done: 1276/2000 images\n",
      "Done: 1277/2000 images\n",
      "Done: 1278/2000 images\n",
      "Done: 1279/2000 images\n",
      "Done: 1280/2000 images\n",
      "Done: 1281/2000 images\n",
      "Done: 1282/2000 images\n",
      "Done: 1283/2000 images\n",
      "Done: 1284/2000 images\n",
      "Done: 1285/2000 images\n",
      "Done: 1286/2000 images\n",
      "Done: 1287/2000 images\n",
      "Done: 1288/2000 images\n",
      "Done: 1289/2000 images\n",
      "Done: 1290/2000 images\n",
      "Done: 1291/2000 images\n",
      "Done: 1292/2000 images\n",
      "Done: 1293/2000 images\n",
      "Done: 1294/2000 images\n",
      "Done: 1295/2000 images\n",
      "Done: 1296/2000 images\n",
      "Done: 1297/2000 images\n",
      "Done: 1298/2000 images\n",
      "Done: 1299/2000 images\n",
      "Done: 1300/2000 images\n",
      "Done: 1301/2000 images\n",
      "Done: 1302/2000 images\n",
      "Done: 1303/2000 images\n",
      "Done: 1304/2000 images\n",
      "Done: 1305/2000 images\n",
      "Done: 1306/2000 images\n",
      "Done: 1307/2000 images\n",
      "Done: 1308/2000 images\n",
      "Done: 1309/2000 images\n",
      "Done: 1310/2000 images\n",
      "Done: 1311/2000 images\n",
      "Done: 1312/2000 images\n",
      "Done: 1313/2000 images\n",
      "Done: 1314/2000 images\n",
      "Done: 1315/2000 images\n",
      "Done: 1316/2000 images\n",
      "Done: 1317/2000 images\n",
      "Done: 1318/2000 images\n",
      "Done: 1319/2000 images\n",
      "Done: 1320/2000 images\n",
      "Done: 1321/2000 images\n",
      "Done: 1322/2000 images\n",
      "Done: 1323/2000 images\n",
      "Done: 1324/2000 images\n",
      "Done: 1325/2000 images\n",
      "Done: 1326/2000 images\n",
      "Done: 1327/2000 images\n",
      "Done: 1328/2000 images\n",
      "Done: 1329/2000 images\n",
      "Done: 1330/2000 images\n",
      "Done: 1331/2000 images\n",
      "Done: 1332/2000 images\n",
      "Done: 1333/2000 images\n",
      "Done: 1334/2000 images\n",
      "Done: 1335/2000 images\n",
      "Done: 1336/2000 images\n",
      "Done: 1337/2000 images\n",
      "Done: 1338/2000 images\n",
      "Done: 1339/2000 images\n",
      "Done: 1340/2000 images\n",
      "Done: 1341/2000 images\n",
      "Done: 1342/2000 images\n",
      "Done: 1343/2000 images\n",
      "Done: 1344/2000 images\n",
      "Done: 1345/2000 images\n",
      "Done: 1346/2000 images\n",
      "Done: 1347/2000 images\n",
      "Done: 1348/2000 images\n",
      "Done: 1349/2000 images\n",
      "Done: 1350/2000 images\n",
      "Done: 1351/2000 images\n",
      "Done: 1352/2000 images\n",
      "Done: 1353/2000 images\n",
      "Done: 1354/2000 images\n",
      "Done: 1355/2000 images\n",
      "Done: 1356/2000 images\n",
      "Done: 1357/2000 images\n",
      "Done: 1358/2000 images\n",
      "Done: 1359/2000 images\n",
      "Done: 1360/2000 images\n",
      "Done: 1361/2000 images\n",
      "Done: 1362/2000 images\n",
      "Done: 1363/2000 images\n",
      "Done: 1364/2000 images\n",
      "Done: 1365/2000 images\n",
      "Done: 1366/2000 images\n",
      "Done: 1367/2000 images\n",
      "Done: 1368/2000 images\n",
      "Done: 1369/2000 images\n",
      "Done: 1370/2000 images\n",
      "Done: 1371/2000 images\n",
      "Done: 1372/2000 images\n",
      "Done: 1373/2000 images\n",
      "Done: 1374/2000 images\n",
      "Done: 1375/2000 images\n",
      "Done: 1376/2000 images\n",
      "Done: 1377/2000 images\n",
      "Done: 1378/2000 images\n",
      "Done: 1379/2000 images\n",
      "Done: 1380/2000 images\n",
      "Done: 1381/2000 images\n",
      "Done: 1382/2000 images\n",
      "Done: 1383/2000 images\n",
      "Done: 1384/2000 images\n",
      "Done: 1385/2000 images\n",
      "Done: 1386/2000 images\n",
      "Done: 1387/2000 images\n",
      "Done: 1388/2000 images\n",
      "Done: 1389/2000 images\n",
      "Done: 1390/2000 images\n",
      "Done: 1391/2000 images\n",
      "Done: 1392/2000 images\n",
      "Done: 1393/2000 images\n",
      "Done: 1394/2000 images\n",
      "Done: 1395/2000 images\n",
      "Done: 1396/2000 images\n",
      "Done: 1397/2000 images\n",
      "Done: 1398/2000 images\n",
      "Done: 1399/2000 images\n",
      "Done: 1400/2000 images\n",
      "Done: 1401/2000 images\n",
      "Done: 1402/2000 images\n",
      "Done: 1403/2000 images\n",
      "Done: 1404/2000 images\n",
      "Done: 1405/2000 images\n",
      "Done: 1406/2000 images\n",
      "Done: 1407/2000 images\n",
      "Done: 1408/2000 images\n",
      "Done: 1409/2000 images\n",
      "Done: 1410/2000 images\n",
      "Done: 1411/2000 images\n",
      "Done: 1412/2000 images\n",
      "Done: 1413/2000 images\n",
      "Done: 1414/2000 images\n",
      "Done: 1415/2000 images\n",
      "Done: 1416/2000 images\n",
      "Done: 1417/2000 images\n",
      "Done: 1418/2000 images\n",
      "Done: 1419/2000 images\n",
      "Done: 1420/2000 images\n",
      "Done: 1421/2000 images\n",
      "Done: 1422/2000 images\n",
      "Done: 1423/2000 images\n",
      "Done: 1424/2000 images\n",
      "Done: 1425/2000 images\n",
      "Done: 1426/2000 images\n",
      "Done: 1427/2000 images\n",
      "Done: 1428/2000 images\n",
      "Done: 1429/2000 images\n",
      "Done: 1430/2000 images\n",
      "Done: 1431/2000 images\n",
      "Done: 1432/2000 images\n",
      "Done: 1433/2000 images\n",
      "Done: 1434/2000 images\n",
      "Done: 1435/2000 images\n",
      "Done: 1436/2000 images\n",
      "Done: 1437/2000 images\n",
      "Done: 1438/2000 images\n",
      "Done: 1439/2000 images\n",
      "Done: 1440/2000 images\n",
      "Done: 1441/2000 images\n",
      "Done: 1442/2000 images\n",
      "Done: 1443/2000 images\n",
      "Done: 1444/2000 images\n",
      "Done: 1445/2000 images\n",
      "Done: 1446/2000 images\n",
      "Done: 1447/2000 images\n",
      "Done: 1448/2000 images\n",
      "Done: 1449/2000 images\n",
      "Done: 1450/2000 images\n",
      "Done: 1451/2000 images\n",
      "Done: 1452/2000 images\n",
      "Done: 1453/2000 images\n",
      "Done: 1454/2000 images\n",
      "Done: 1455/2000 images\n",
      "Done: 1456/2000 images\n",
      "Done: 1457/2000 images\n",
      "Done: 1458/2000 images\n",
      "Done: 1459/2000 images\n",
      "Done: 1460/2000 images\n",
      "Done: 1461/2000 images\n",
      "Done: 1462/2000 images\n",
      "Done: 1463/2000 images\n",
      "Done: 1464/2000 images\n",
      "Done: 1465/2000 images\n",
      "Done: 1466/2000 images\n",
      "Done: 1467/2000 images\n",
      "Done: 1468/2000 images\n",
      "Done: 1469/2000 images\n",
      "Done: 1470/2000 images\n",
      "Done: 1471/2000 images\n",
      "Done: 1472/2000 images\n",
      "Done: 1473/2000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1474/2000 images\n",
      "Done: 1475/2000 images\n",
      "Done: 1476/2000 images\n",
      "Done: 1477/2000 images\n",
      "Done: 1478/2000 images\n",
      "Done: 1479/2000 images\n",
      "Done: 1480/2000 images\n",
      "Done: 1481/2000 images\n",
      "Done: 1482/2000 images\n",
      "Done: 1483/2000 images\n",
      "Done: 1484/2000 images\n",
      "Done: 1485/2000 images\n",
      "Done: 1486/2000 images\n",
      "Done: 1487/2000 images\n",
      "Done: 1488/2000 images\n",
      "Done: 1489/2000 images\n",
      "Done: 1490/2000 images\n",
      "Done: 1491/2000 images\n",
      "Done: 1492/2000 images\n",
      "Done: 1493/2000 images\n",
      "Done: 1494/2000 images\n",
      "Done: 1495/2000 images\n",
      "Done: 1496/2000 images\n",
      "Done: 1497/2000 images\n",
      "Done: 1498/2000 images\n",
      "Done: 1499/2000 images\n",
      "Done: 1500/2000 images\n",
      "Done: 1501/2000 images\n",
      "Done: 1502/2000 images\n",
      "Done: 1503/2000 images\n",
      "Done: 1504/2000 images\n",
      "Done: 1505/2000 images\n",
      "Done: 1506/2000 images\n",
      "Done: 1507/2000 images\n",
      "Done: 1508/2000 images\n",
      "Done: 1509/2000 images\n",
      "Done: 1510/2000 images\n",
      "Done: 1511/2000 images\n",
      "Done: 1512/2000 images\n",
      "Done: 1513/2000 images\n",
      "Done: 1514/2000 images\n",
      "Done: 1515/2000 images\n",
      "Done: 1516/2000 images\n",
      "Done: 1517/2000 images\n",
      "Done: 1518/2000 images\n",
      "Done: 1519/2000 images\n",
      "Done: 1520/2000 images\n",
      "Done: 1521/2000 images\n",
      "Done: 1522/2000 images\n",
      "Done: 1523/2000 images\n",
      "Done: 1524/2000 images\n",
      "Done: 1525/2000 images\n",
      "Done: 1526/2000 images\n",
      "Done: 1527/2000 images\n",
      "Done: 1528/2000 images\n",
      "Done: 1529/2000 images\n",
      "Done: 1530/2000 images\n",
      "Done: 1531/2000 images\n",
      "Done: 1532/2000 images\n",
      "Done: 1533/2000 images\n",
      "Done: 1534/2000 images\n",
      "Done: 1535/2000 images\n",
      "Done: 1536/2000 images\n",
      "Done: 1537/2000 images\n",
      "Done: 1538/2000 images\n",
      "Done: 1539/2000 images\n",
      "Done: 1540/2000 images\n",
      "Done: 1541/2000 images\n",
      "Done: 1542/2000 images\n",
      "Done: 1543/2000 images\n",
      "Done: 1544/2000 images\n",
      "Done: 1545/2000 images\n",
      "Done: 1546/2000 images\n",
      "Done: 1547/2000 images\n",
      "Done: 1548/2000 images\n",
      "Done: 1549/2000 images\n",
      "Done: 1550/2000 images\n",
      "Done: 1551/2000 images\n",
      "Done: 1552/2000 images\n",
      "Done: 1553/2000 images\n",
      "Done: 1554/2000 images\n",
      "Done: 1555/2000 images\n",
      "Done: 1556/2000 images\n",
      "Done: 1557/2000 images\n",
      "Done: 1558/2000 images\n",
      "Done: 1559/2000 images\n",
      "Done: 1560/2000 images\n",
      "Done: 1561/2000 images\n",
      "Done: 1562/2000 images\n",
      "Done: 1563/2000 images\n",
      "Done: 1564/2000 images\n",
      "Done: 1565/2000 images\n",
      "Done: 1566/2000 images\n",
      "Done: 1567/2000 images\n",
      "Done: 1568/2000 images\n",
      "Done: 1569/2000 images\n",
      "Done: 1570/2000 images\n",
      "Done: 1571/2000 images\n",
      "Done: 1572/2000 images\n",
      "Done: 1573/2000 images\n",
      "Done: 1574/2000 images\n",
      "Done: 1575/2000 images\n",
      "Done: 1576/2000 images\n",
      "Done: 1577/2000 images\n",
      "Done: 1578/2000 images\n",
      "Done: 1579/2000 images\n",
      "Done: 1580/2000 images\n",
      "Done: 1581/2000 images\n",
      "Done: 1582/2000 images\n",
      "Done: 1583/2000 images\n",
      "Done: 1584/2000 images\n",
      "Done: 1585/2000 images\n",
      "Done: 1586/2000 images\n",
      "Done: 1587/2000 images\n",
      "Done: 1588/2000 images\n",
      "Done: 1589/2000 images\n",
      "Done: 1590/2000 images\n",
      "Done: 1591/2000 images\n",
      "Done: 1592/2000 images\n",
      "Done: 1593/2000 images\n",
      "Done: 1594/2000 images\n",
      "Done: 1595/2000 images\n",
      "Done: 1596/2000 images\n",
      "Done: 1597/2000 images\n",
      "Done: 1598/2000 images\n",
      "Done: 1599/2000 images\n",
      "Done: 1600/2000 images\n",
      "Done: 1601/2000 images\n",
      "Done: 1602/2000 images\n",
      "Done: 1603/2000 images\n",
      "Done: 1604/2000 images\n",
      "Done: 1605/2000 images\n",
      "Done: 1606/2000 images\n",
      "Done: 1607/2000 images\n",
      "Done: 1608/2000 images\n",
      "Done: 1609/2000 images\n",
      "Done: 1610/2000 images\n",
      "Done: 1611/2000 images\n",
      "Done: 1612/2000 images\n",
      "Done: 1613/2000 images\n",
      "Done: 1614/2000 images\n",
      "Done: 1615/2000 images\n",
      "Done: 1616/2000 images\n",
      "Done: 1617/2000 images\n",
      "Done: 1618/2000 images\n",
      "Done: 1619/2000 images\n",
      "Done: 1620/2000 images\n",
      "Done: 1621/2000 images\n",
      "Done: 1622/2000 images\n",
      "Done: 1623/2000 images\n",
      "Done: 1624/2000 images\n",
      "Done: 1625/2000 images\n",
      "Done: 1626/2000 images\n",
      "Done: 1627/2000 images\n",
      "Done: 1628/2000 images\n",
      "Done: 1629/2000 images\n",
      "Done: 1630/2000 images\n",
      "Done: 1631/2000 images\n",
      "Done: 1632/2000 images\n",
      "Done: 1633/2000 images\n",
      "Done: 1634/2000 images\n",
      "Done: 1635/2000 images\n",
      "Done: 1636/2000 images\n",
      "Done: 1637/2000 images\n",
      "Done: 1638/2000 images\n",
      "Done: 1639/2000 images\n",
      "Done: 1640/2000 images\n",
      "Done: 1641/2000 images\n",
      "Done: 1642/2000 images\n",
      "Done: 1643/2000 images\n",
      "Done: 1644/2000 images\n",
      "Done: 1645/2000 images\n",
      "Done: 1646/2000 images\n",
      "Done: 1647/2000 images\n",
      "Done: 1648/2000 images\n",
      "Done: 1649/2000 images\n",
      "Done: 1650/2000 images\n",
      "Done: 1651/2000 images\n",
      "Done: 1652/2000 images\n",
      "Done: 1653/2000 images\n",
      "Done: 1654/2000 images\n",
      "Done: 1655/2000 images\n",
      "Done: 1656/2000 images\n",
      "Done: 1657/2000 images\n",
      "Done: 1658/2000 images\n",
      "Done: 1659/2000 images\n",
      "Done: 1660/2000 images\n",
      "Done: 1661/2000 images\n",
      "Done: 1662/2000 images\n",
      "Done: 1663/2000 images\n",
      "Done: 1664/2000 images\n",
      "Done: 1665/2000 images\n",
      "Done: 1666/2000 images\n",
      "Done: 1667/2000 images\n",
      "Done: 1668/2000 images\n",
      "Done: 1669/2000 images\n",
      "Done: 1670/2000 images\n",
      "Done: 1671/2000 images\n",
      "Done: 1672/2000 images\n",
      "Done: 1673/2000 images\n",
      "Done: 1674/2000 images\n",
      "Done: 1675/2000 images\n",
      "Done: 1676/2000 images\n",
      "Done: 1677/2000 images\n",
      "Done: 1678/2000 images\n",
      "Done: 1679/2000 images\n",
      "Done: 1680/2000 images\n",
      "Done: 1681/2000 images\n",
      "Done: 1682/2000 images\n",
      "Done: 1683/2000 images\n",
      "Done: 1684/2000 images\n",
      "Done: 1685/2000 images\n",
      "Done: 1686/2000 images\n",
      "Done: 1687/2000 images\n",
      "Done: 1688/2000 images\n",
      "Done: 1689/2000 images\n",
      "Done: 1690/2000 images\n",
      "Done: 1691/2000 images\n",
      "Done: 1692/2000 images\n",
      "Done: 1693/2000 images\n",
      "Done: 1694/2000 images\n",
      "Done: 1695/2000 images\n",
      "Done: 1696/2000 images\n",
      "Done: 1697/2000 images\n",
      "Done: 1698/2000 images\n",
      "Done: 1699/2000 images\n",
      "Done: 1700/2000 images\n",
      "Done: 1701/2000 images\n",
      "Done: 1702/2000 images\n",
      "Done: 1703/2000 images\n",
      "Done: 1704/2000 images\n",
      "Done: 1705/2000 images\n",
      "Done: 1706/2000 images\n",
      "Done: 1707/2000 images\n",
      "Done: 1708/2000 images\n",
      "Done: 1709/2000 images\n",
      "Done: 1710/2000 images\n",
      "Done: 1711/2000 images\n",
      "Done: 1712/2000 images\n",
      "Done: 1713/2000 images\n",
      "Done: 1714/2000 images\n",
      "Done: 1715/2000 images\n",
      "Done: 1716/2000 images\n",
      "Done: 1717/2000 images\n",
      "Done: 1718/2000 images\n",
      "Done: 1719/2000 images\n",
      "Done: 1720/2000 images\n",
      "Done: 1721/2000 images\n",
      "Done: 1722/2000 images\n",
      "Done: 1723/2000 images\n",
      "Done: 1724/2000 images\n",
      "Done: 1725/2000 images\n",
      "Done: 1726/2000 images\n",
      "Done: 1727/2000 images\n",
      "Done: 1728/2000 images\n",
      "Done: 1729/2000 images\n",
      "Done: 1730/2000 images\n",
      "Done: 1731/2000 images\n",
      "Done: 1732/2000 images\n",
      "Done: 1733/2000 images\n",
      "Done: 1734/2000 images\n",
      "Done: 1735/2000 images\n",
      "Done: 1736/2000 images\n",
      "Done: 1737/2000 images\n",
      "Done: 1738/2000 images\n",
      "Done: 1739/2000 images\n",
      "Done: 1740/2000 images\n",
      "Done: 1741/2000 images\n",
      "Done: 1742/2000 images\n",
      "Done: 1743/2000 images\n",
      "Done: 1744/2000 images\n",
      "Done: 1745/2000 images\n",
      "Done: 1746/2000 images\n",
      "Done: 1747/2000 images\n",
      "Done: 1748/2000 images\n",
      "Done: 1749/2000 images\n",
      "Done: 1750/2000 images\n",
      "Done: 1751/2000 images\n",
      "Done: 1752/2000 images\n",
      "Done: 1753/2000 images\n",
      "Done: 1754/2000 images\n",
      "Done: 1755/2000 images\n",
      "Done: 1756/2000 images\n",
      "Done: 1757/2000 images\n",
      "Done: 1758/2000 images\n",
      "Done: 1759/2000 images\n",
      "Done: 1760/2000 images\n",
      "Done: 1761/2000 images\n",
      "Done: 1762/2000 images\n",
      "Done: 1763/2000 images\n",
      "Done: 1764/2000 images\n",
      "Done: 1765/2000 images\n",
      "Done: 1766/2000 images\n",
      "Done: 1767/2000 images\n",
      "Done: 1768/2000 images\n",
      "Done: 1769/2000 images\n",
      "Done: 1770/2000 images\n",
      "Done: 1771/2000 images\n",
      "Done: 1772/2000 images\n",
      "Done: 1773/2000 images\n",
      "Done: 1774/2000 images\n",
      "Done: 1775/2000 images\n",
      "Done: 1776/2000 images\n",
      "Done: 1777/2000 images\n",
      "Done: 1778/2000 images\n",
      "Done: 1779/2000 images\n",
      "Done: 1780/2000 images\n",
      "Done: 1781/2000 images\n",
      "Done: 1782/2000 images\n",
      "Done: 1783/2000 images\n",
      "Done: 1784/2000 images\n",
      "Done: 1785/2000 images\n",
      "Done: 1786/2000 images\n",
      "Done: 1787/2000 images\n",
      "Done: 1788/2000 images\n",
      "Done: 1789/2000 images\n",
      "Done: 1790/2000 images\n",
      "Done: 1791/2000 images\n",
      "Done: 1792/2000 images\n",
      "Done: 1793/2000 images\n",
      "Done: 1794/2000 images\n",
      "Done: 1795/2000 images\n",
      "Done: 1796/2000 images\n",
      "Done: 1797/2000 images\n",
      "Done: 1798/2000 images\n",
      "Done: 1799/2000 images\n",
      "Done: 1800/2000 images\n",
      "Done: 1801/2000 images\n",
      "Done: 1802/2000 images\n",
      "Done: 1803/2000 images\n",
      "Done: 1804/2000 images\n",
      "Done: 1805/2000 images\n",
      "Done: 1806/2000 images\n",
      "Done: 1807/2000 images\n",
      "Done: 1808/2000 images\n",
      "Done: 1809/2000 images\n",
      "Done: 1810/2000 images\n",
      "Done: 1811/2000 images\n",
      "Done: 1812/2000 images\n",
      "Done: 1813/2000 images\n",
      "Done: 1814/2000 images\n",
      "Done: 1815/2000 images\n",
      "Done: 1816/2000 images\n",
      "Done: 1817/2000 images\n",
      "Done: 1818/2000 images\n",
      "Done: 1819/2000 images\n",
      "Done: 1820/2000 images\n",
      "Done: 1821/2000 images\n",
      "Done: 1822/2000 images\n",
      "Done: 1823/2000 images\n",
      "Done: 1824/2000 images\n",
      "Done: 1825/2000 images\n",
      "Done: 1826/2000 images\n",
      "Done: 1827/2000 images\n",
      "Done: 1828/2000 images\n",
      "Done: 1829/2000 images\n",
      "Done: 1830/2000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1831/2000 images\n",
      "Done: 1832/2000 images\n",
      "Done: 1833/2000 images\n",
      "Done: 1834/2000 images\n",
      "Done: 1835/2000 images\n",
      "Done: 1836/2000 images\n",
      "Done: 1837/2000 images\n",
      "Done: 1838/2000 images\n",
      "Done: 1839/2000 images\n",
      "Done: 1840/2000 images\n",
      "Done: 1841/2000 images\n",
      "Done: 1842/2000 images\n",
      "Done: 1843/2000 images\n",
      "Done: 1844/2000 images\n",
      "Done: 1845/2000 images\n",
      "Done: 1846/2000 images\n",
      "Done: 1847/2000 images\n",
      "Done: 1848/2000 images\n",
      "Done: 1849/2000 images\n",
      "Done: 1850/2000 images\n",
      "Done: 1851/2000 images\n",
      "Done: 1852/2000 images\n",
      "Done: 1853/2000 images\n",
      "Done: 1854/2000 images\n",
      "Done: 1855/2000 images\n",
      "Done: 1856/2000 images\n",
      "Done: 1857/2000 images\n",
      "Done: 1858/2000 images\n",
      "Done: 1859/2000 images\n",
      "Done: 1860/2000 images\n",
      "Done: 1861/2000 images\n",
      "Done: 1862/2000 images\n",
      "Done: 1863/2000 images\n",
      "Done: 1864/2000 images\n",
      "Done: 1865/2000 images\n",
      "Done: 1866/2000 images\n",
      "Done: 1867/2000 images\n",
      "Done: 1868/2000 images\n",
      "Done: 1869/2000 images\n",
      "Done: 1870/2000 images\n",
      "Done: 1871/2000 images\n",
      "Done: 1872/2000 images\n",
      "Done: 1873/2000 images\n",
      "Done: 1874/2000 images\n",
      "Done: 1875/2000 images\n",
      "Done: 1876/2000 images\n",
      "Done: 1877/2000 images\n",
      "Done: 1878/2000 images\n",
      "Done: 1879/2000 images\n",
      "Done: 1880/2000 images\n",
      "Done: 1881/2000 images\n",
      "Done: 1882/2000 images\n",
      "Done: 1883/2000 images\n",
      "Done: 1884/2000 images\n",
      "Done: 1885/2000 images\n",
      "Done: 1886/2000 images\n",
      "Done: 1887/2000 images\n",
      "Done: 1888/2000 images\n",
      "Done: 1889/2000 images\n",
      "Done: 1890/2000 images\n",
      "Done: 1891/2000 images\n",
      "Done: 1892/2000 images\n",
      "Done: 1893/2000 images\n",
      "Done: 1894/2000 images\n",
      "Done: 1895/2000 images\n",
      "Done: 1896/2000 images\n",
      "Done: 1897/2000 images\n",
      "Done: 1898/2000 images\n",
      "Done: 1899/2000 images\n",
      "Done: 1900/2000 images\n",
      "Done: 1901/2000 images\n",
      "Done: 1902/2000 images\n",
      "Done: 1903/2000 images\n",
      "Done: 1904/2000 images\n",
      "Done: 1905/2000 images\n",
      "Done: 1906/2000 images\n",
      "Done: 1907/2000 images\n",
      "Done: 1908/2000 images\n",
      "Done: 1909/2000 images\n",
      "Done: 1910/2000 images\n",
      "Done: 1911/2000 images\n",
      "Done: 1912/2000 images\n",
      "Done: 1913/2000 images\n",
      "Done: 1914/2000 images\n",
      "Done: 1915/2000 images\n",
      "Done: 1916/2000 images\n",
      "Done: 1917/2000 images\n",
      "Done: 1918/2000 images\n",
      "Done: 1919/2000 images\n",
      "Done: 1920/2000 images\n",
      "Done: 1921/2000 images\n",
      "Done: 1922/2000 images\n",
      "Done: 1923/2000 images\n",
      "Done: 1924/2000 images\n",
      "Done: 1925/2000 images\n",
      "Done: 1926/2000 images\n",
      "Done: 1927/2000 images\n",
      "Done: 1928/2000 images\n",
      "Done: 1929/2000 images\n",
      "Done: 1930/2000 images\n",
      "Done: 1931/2000 images\n",
      "Done: 1932/2000 images\n",
      "Done: 1933/2000 images\n",
      "Done: 1934/2000 images\n",
      "Done: 1935/2000 images\n",
      "Done: 1936/2000 images\n",
      "Done: 1937/2000 images\n",
      "Done: 1938/2000 images\n",
      "Done: 1939/2000 images\n",
      "Done: 1940/2000 images\n",
      "Done: 1941/2000 images\n",
      "Done: 1942/2000 images\n",
      "Done: 1943/2000 images\n",
      "Done: 1944/2000 images\n",
      "Done: 1945/2000 images\n",
      "Done: 1946/2000 images\n",
      "Done: 1947/2000 images\n",
      "Done: 1948/2000 images\n",
      "Done: 1949/2000 images\n",
      "Done: 1950/2000 images\n",
      "Done: 1951/2000 images\n",
      "Done: 1952/2000 images\n",
      "Done: 1953/2000 images\n",
      "Done: 1954/2000 images\n",
      "Done: 1955/2000 images\n",
      "Done: 1956/2000 images\n",
      "Done: 1957/2000 images\n",
      "Done: 1958/2000 images\n",
      "Done: 1959/2000 images\n",
      "Done: 1960/2000 images\n",
      "Done: 1961/2000 images\n",
      "Done: 1962/2000 images\n",
      "Done: 1963/2000 images\n",
      "Done: 1964/2000 images\n",
      "Done: 1965/2000 images\n",
      "Done: 1966/2000 images\n",
      "Done: 1967/2000 images\n",
      "Done: 1968/2000 images\n",
      "Done: 1969/2000 images\n",
      "Done: 1970/2000 images\n",
      "Done: 1971/2000 images\n",
      "Done: 1972/2000 images\n",
      "Done: 1973/2000 images\n",
      "Done: 1974/2000 images\n",
      "Done: 1975/2000 images\n",
      "Done: 1976/2000 images\n",
      "Done: 1977/2000 images\n",
      "Done: 1978/2000 images\n",
      "Done: 1979/2000 images\n",
      "Done: 1980/2000 images\n",
      "Done: 1981/2000 images\n",
      "Done: 1982/2000 images\n",
      "Done: 1983/2000 images\n",
      "Done: 1984/2000 images\n",
      "Done: 1985/2000 images\n",
      "Done: 1986/2000 images\n",
      "Done: 1987/2000 images\n",
      "Done: 1988/2000 images\n",
      "Done: 1989/2000 images\n",
      "Done: 1990/2000 images\n",
      "Done: 1991/2000 images\n",
      "Done: 1992/2000 images\n",
      "Done: 1993/2000 images\n",
      "Done: 1994/2000 images\n",
      "Done: 1995/2000 images\n",
      "Done: 1996/2000 images\n",
      "Done: 1997/2000 images\n",
      "Done: 1998/2000 images\n",
      "Done: 1999/2000 images\n",
      "out of for\n",
      "Loading done.\n"
     ]
    }
   ],
   "source": [
    "resize_h=256\n",
    "resize_w=256\n",
    "\n",
    "def load_data():\n",
    "    total=len(os.listdir('melanoma/'))+len(os.listdir('others/'))\n",
    "    print(total)\n",
    "    imgs=[]\n",
    "    imgs_mask=[]\n",
    "    labels=[]\n",
    "    i = 0\n",
    "    images = os.listdir('melanoma/')\n",
    "    for image_name in images:\n",
    "        image_mask_name = image_name.split('.')[0]\n",
    "        image_mask_name = image_mask_name+\"_segmentation.png\"\n",
    "        img = ndimage.imread('melanoma/'+image_name)       \n",
    "        #img = cv2.resize(img, (resize_h, resize_w))\n",
    "        img_mask = ndimage.imread('gt/'+image_mask_name)\n",
    "        #print(size(imgs_mask))\n",
    "        #img_mask = cv2.res(img_mask, (array.shape[1], array.shape[0],1))\n",
    "        #img = np.multiply(img ,img_mask/255.)\n",
    "        #img = imresize(img,(resize_h,resize_w))\n",
    "        #ret2,th2 = cv2.threshold(img_mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        labels.append(1)\n",
    "        img = img_to_array(img)\n",
    "        img_mask=img_to_array(img_mask)\n",
    "        img_mask=np.reshape(img_mask,(img_mask.shape[0],img_mask.shape[1],1))\n",
    "        img = np.multiply(img ,img_mask/255.)\n",
    "        img = imresize(img,(resize_h,resize_w))\n",
    "        imgs.append(img)\n",
    "        #imgs_mask.append(img_mask)\n",
    "        print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    images = os.listdir('others/')\n",
    "    for image_name in images:\n",
    "        image_mask_name = image_name.split('.')[0]\n",
    "        image_mask_name = image_mask_name+\"_segmentation.png\"\n",
    "        img = ndimage.imread('others/'+image_name)       \n",
    "        #img = cv2.resize(img, (resize_h, resize_w))\n",
    "        img_mask = ndimage.imread('gt/'+image_mask_name)\n",
    "        #print(size(imgs_mask))\n",
    "        #img_mask = cv2.res(img_mask, (array.shape[1], array.shape[0],1))\n",
    "        #img = np.multiply(img ,img_mask/255.)\n",
    "        #img = imresize(img,(resize_h,resize_w))\n",
    "        #ret2,th2 = cv2.threshold(img_mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        labels.append(0)\n",
    "        img = img_to_array(img)\n",
    "        img_mask=img_to_array(img_mask)\n",
    "        img_mask=np.reshape(img_mask,(img_mask.shape[0],img_mask.shape[1],1))\n",
    "        img = np.multiply(img ,img_mask/255.)\n",
    "        img = imresize(img,(resize_h,resize_w))\n",
    "        imgs.append(img)\n",
    "        print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('out of for')\n",
    "    imgs = np.array(imgs, dtype=\"float\")\n",
    "    imgs_mask = np.array(imgs_mask,dtype=\"float\")\n",
    "    labels = np.array(labels,dtype='float')\n",
    "    print('Loading done.')\n",
    "    return imgs, labels\n",
    "\n",
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save( 'images.npy', X)\n",
    "np.save('labels.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../imgs_classify.npy')\n",
    "Y = np.load('../labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5bd099f050>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/yWeaACtDcjRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d3ecc5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.67186529e-16,   2.22915381e-16, ...,\n",
       "         9.99998152e-01,   9.99998689e-01,   1.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,name = \"Cf.png\",\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig = plt.gcf()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_network(x):\n",
    "    \"\"\"\n",
    "    ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "    \n",
    "    \"\"\"\n",
    "    def add_common_layers(y):\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.Activation('relu')(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def grouped_convolution(y, nb_channels, _strides):\n",
    "        # when `cardinality` == 1 this is just a standard convolution\n",
    "        if cardinality == 1:\n",
    "            return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        \n",
    "        assert not nb_channels % cardinality\n",
    "        _d = nb_channels // cardinality\n",
    "\n",
    "        # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "        # and convolutions are separately performed within each group\n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "            \n",
    "        # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "        y = layers.concatenate(groups)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "        and are subject to two simple rules:\n",
    "        - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "        - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "        \"\"\"\n",
    "        shortcut = y\n",
    "\n",
    "        # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "        y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            # when the dimensions increase projection shortcut is used to match dimensions (done by 11 convolutions)\n",
    "            # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = layers.add([shortcut, y])\n",
    "\n",
    "        # relu is performed right after each batch normalization,\n",
    "        # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "        y = layers.Activation('relu')(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    # conv1\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    # conv2\n",
    "    x = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    for i in range(3):\n",
    "        project_shortcut = True if i == 0 else False\n",
    "        x = residual_block(x, 128, 256, _project_shortcut=project_shortcut)\n",
    "\n",
    "    # conv3\n",
    "    for i in range(4):\n",
    "        # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 256, 512, _strides=strides)\n",
    "\n",
    "    # conv4\n",
    "    for i in range(6):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 512, 1024, _strides=strides)\n",
    "\n",
    "    # conv5\n",
    "    for i in range(3):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 1024, 2048, _strides=strides)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 64) 9472        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  8320        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  33024       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  32896       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  33024       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 512)  131584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 512)  2048        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 256)  131328      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 256)  1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 256)  590080      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 512)  131584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 512)  2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           activation_13[0][0]              \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 256)  131328      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 256)  590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 512)  131584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 512)  2048        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 256)  131328      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 512)  131584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 512)  2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           activation_19[0][0]              \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 512)  262656      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 512)  2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 512)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 512)  2359808     activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 512)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 1024) 525312      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 1024) 4096        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           batch_normalization_35[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 512)  524800      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 512)  2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 512)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 512)  2359808     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 512)  2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 512)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 1024) 525312      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 1024) 4096        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           activation_25[0][0]              \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 512)  524800      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 512)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 512)  2359808     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 512)  2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 512)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 1024) 525312      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 1024) 4096        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           activation_28[0][0]              \n",
      "                                                                 batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 512)  524800      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 512)  2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 512)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 512)  2359808     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 512)  2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 512)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 1024) 525312      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 1024) 4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           activation_31[0][0]              \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 512)  524800      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 512)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 512)  2359808     activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 512)  2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 512)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 1024) 525312      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 1024) 4096        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           activation_34[0][0]              \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 512)  524800      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 512)  2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 512)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 512)  2359808     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 512)  2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 512)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 1024) 525312      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 1024) 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           activation_37[0][0]              \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 1024) 1049600     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 1024) 4096        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 1024) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 1024)   4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 2048)   2099200     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 2048)   8192        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 2048)   8192        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           batch_normalization_54[0][0]     \n",
      "                                                                 batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 1024)   2098176     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 1024)   4096        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 1024)   4096        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 2048)   2099200     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 2048)   8192        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           activation_43[0][0]              \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 1024)   2098176     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 1024)   4096        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 1024)   4096        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 2048)   2099200     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 2048)   8192        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           activation_46[0][0]              \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            2049        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 66,938,625\n",
      "Trainable params: 66,870,401\n",
      "Non-trainable params: 68,224\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cardinality = 1\n",
    "image_tensor = layers.Input(shape=(256, 256, 3))\n",
    "network_output = residual_network(image_tensor)\n",
    "  \n",
    "resnext = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "print(resnext.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnext.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy',f1_score,recall,precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint2 = ModelCheckpoint('resnext_classification2.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 4014s 3s/step - loss: 2.0116 - acc: 0.5000 - f1_score: nan - recall: 0.6954 - precision: 0.2564 - val_loss: 1.8218 - val_acc: 0.5400 - val_f1_score: nan - val_recall: 0.8800 - val_precision: 0.3030\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 4355s 3s/step - loss: 1.4790 - acc: 0.5206 - f1_score: nan - recall: 0.7007 - precision: 0.2657 - val_loss: 0.4316 - val_acc: 0.8000 - val_f1_score: nan - val_recall: 0.1517 - val_precision: 0.2133\n",
      "Epoch 3/10\n",
      "  80/1600 [>.............................] - ETA: 1:05:30 - loss: 0.7341 - acc: 0.7875 - f1_score: nan - recall: 0.6000 - precision: 0.3333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9c2674ae5698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/gated_cnn_autoencoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = resnext.fit(trainX,trainY, batch_size = 8, epochs = 10, verbose = True, validation_data = (testX, testY),callbacks=[TensorBoard(log_dir='/tmp/gated_cnn_autoencoder', histogram_freq=0,write_graph=True)],class_weight={0: 1, 1: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = resnext.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction >= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Non-Melanoma', 'Melanoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.96273292  0.03726708]\n",
      " [ 0.8974359   0.1025641 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLl0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ba4654d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes=class_names,normalize= True,\n",
    "                      name = \"NB_Confusion_matrix_without_normalisation.png\",\n",
    "                      title='Confusion matrix without Normalisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
